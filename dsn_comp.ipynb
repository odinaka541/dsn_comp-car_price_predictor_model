{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5429903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#\n",
    "def load_and_preprocess_data(df, is_training=True, brand_map=None, model_map=None, encoders=None):\n",
    "   \n",
    "    df = df.copy()\n",
    "    \n",
    "    # handle missing data intelligently\n",
    "    df['clean_title'] = df['clean_title'].fillna('Unknown')\n",
    "    df['accident'] = df['accident'].fillna('Unknown')\n",
    "    if df['fuel_type'].isna().any():\n",
    "        df['fuel_type'] = df['fuel_type'].fillna(df['fuel_type'].mode()[0])\n",
    "    \n",
    "    # cap price outliers (training only)\n",
    "    if is_training and 'price' in df.columns:\n",
    "        price_cap = df['price'].quantile(0.99)\n",
    "        df['price'] = df['price'].clip(upper=price_cap)\n",
    "        print(f\"price capped at ${price_cap:,.0f}\")\n",
    "    \n",
    "    # target encoding for high-cardinality categoricals\n",
    "    if is_training:\n",
    "        # create encoding maps from training data\n",
    "        brand_map = df.groupby('brand')['price'].mean().to_dict()\n",
    "        model_map = df.groupby('model')['price'].mean().to_dict()\n",
    "        \n",
    "        df['brand_encoded'] = df['brand'].map(brand_map)\n",
    "        df['model_encoded'] = df['model'].map(model_map)\n",
    "    else:\n",
    "        # apply training maps to test data, use global mean for unseen values\n",
    "        global_brand_mean = np.mean(list(brand_map.values()))\n",
    "        global_model_mean = np.mean(list(model_map.values()))\n",
    "        \n",
    "        df['brand_encoded'] = df['brand'].map(brand_map).fillna(global_brand_mean)\n",
    "        df['model_encoded'] = df['model'].map(model_map).fillna(global_model_mean)\n",
    "    \n",
    "    # parse engine features from text\n",
    "    df['horsepower'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)HP').astype(float)\n",
    "    df['displacement'] = df['engine'].str.extract(r'(\\d+\\.?\\d*)L').astype(float) \n",
    "    df['cylinders'] = df['engine'].str.extract(r'(\\d+) Cylinder').astype(float)\n",
    "    \n",
    "    # handle missing engine features\n",
    "    df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "    df['displacement'] = df['displacement'].fillna(df['displacement'].median())\n",
    "    df['cylinders'] = df['cylinders'].fillna(df['cylinders'].median())\n",
    "    \n",
    "    # create additional engineered features\n",
    "    current_year = 2024\n",
    "    df['car_age'] = current_year - df['model_year']\n",
    "    df['mileage_per_year'] = df['milage'] / (df['car_age'] + 1)\n",
    "    df['hp_per_liter'] = df['horsepower'] / (df['displacement'] + 0.1)  # avoid division by zero\n",
    "    \n",
    "    # encode remaining categorical variables\n",
    "    categorical_cols = ['fuel_type', 'transmission', 'ext_col', 'int_col', 'clean_title', 'accident']\n",
    "    \n",
    "    if is_training:\n",
    "        # create encoders from training data\n",
    "        encoders = {}\n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[col])\n",
    "            encoders[col] = le\n",
    "    else:\n",
    "        # apply training encoders to test data\n",
    "        for col in categorical_cols:\n",
    "            le = encoders[col]\n",
    "            # handle unseen categories by mapping to a default value\n",
    "            df[f'{col}_temp'] = df[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "            df[f'{col}_encoded'] = le.transform(df[f'{col}_temp'])\n",
    "            df.drop(f'{col}_temp', axis=1, inplace=True)\n",
    "    \n",
    "    return df, brand_map, model_map, encoders\n",
    "\n",
    "#\n",
    "def create_feature_matrix(df):\n",
    "\n",
    "    feature_cols = [\n",
    "        'model_year', 'milage', 'brand_encoded', 'model_encoded',\n",
    "        'horsepower', 'displacement', 'cylinders', 'car_age', \n",
    "        'mileage_per_year', 'hp_per_liter',\n",
    "        'fuel_type_encoded', 'transmission_encoded', 'ext_col_encoded',\n",
    "        'int_col_encoded', 'clean_title_encoded', 'accident_encoded'\n",
    "    ]\n",
    "    \n",
    "    return df[feature_cols]\n",
    "\n",
    "#\n",
    "def train_model(X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "#\n",
    "def main():\n",
    "    \"\"\"\n",
    "    main execution pipeline for car price prediction\n",
    "    loads data, preprocesses, trains model, and creates submission\n",
    "    \"\"\"\n",
    "    print(\"loading training data...\")\n",
    "    train_df = pd.read_csv('/kaggle/input/hackathon-qualification/archive/train.csv')\n",
    "    print(f\"training data shape: {train_df.shape}\")\n",
    "    \n",
    "    print(\"loading test data...\")\n",
    "    test_df = pd.read_csv('/kaggle/input/hackathon-qualification/archive/test.csv')\n",
    "    print(f\"test data shape: {test_df.shape}\")\n",
    "    \n",
    "    # preprocess training data\n",
    "    print(\"preprocessing training data...\")\n",
    "    train_processed, brand_map, model_map, encoders = load_and_preprocess_data(\n",
    "        train_df, is_training=True\n",
    "    )\n",
    "    \n",
    "    # create feature matrices\n",
    "    X = create_feature_matrix(train_processed)\n",
    "    y = train_processed['price']\n",
    "    \n",
    "    print(f\"feature matrix shape: {X.shape}\")\n",
    "    print(f\"features: {list(X.columns)}\")\n",
    "    \n",
    "    # train/validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=23\n",
    "    )\n",
    "    \n",
    "    # train model\n",
    "    print(\"training xgboost model...\")\n",
    "    model = train_model(X_train, y_train, X_val, y_val)\n",
    "    \n",
    "    # evaluate on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    \n",
    "    print(f\"validation mae: ${mae:,.0f}\")\n",
    "    print(f\"validation rmse: ${rmse:,.0f}\")\n",
    "    \n",
    "    # feature importance\n",
    "    feature_importance = sorted(\n",
    "        zip(X.columns, model.feature_importances_), \n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "    print(\"\\ntop 5 feature importance:\")\n",
    "    for feature, importance in feature_importance[:5]:\n",
    "        print(f\"{feature}: {importance:.3f}\")\n",
    "    \n",
    "    # preprocess test data using training mappings\n",
    "    print(\"preprocessing test data...\")\n",
    "    test_processed, _, _, _ = load_and_preprocess_data(\n",
    "        test_df, is_training=False, \n",
    "        brand_map=brand_map, model_map=model_map, encoders=encoders\n",
    "    )\n",
    "    \n",
    "    # create test feature matrix\n",
    "    X_test = create_feature_matrix(test_processed)\n",
    "    print(f\"test feature matrix shape: {X_test.shape}\")\n",
    "    \n",
    "    # make predictions\n",
    "    print(\"generating predictions...\")\n",
    "    test_predictions = model.predict(X_test)\n",
    "    \n",
    "    # create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'price': test_predictions.astype(int)\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"submission file created: submission.csv\")\n",
    "    print(f\"submission shape: {submission.shape}\")\n",
    "    print(f\"prediction range: ${submission['price'].min():,} to ${submission['price'].max():,}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
